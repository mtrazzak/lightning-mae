{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Training a Model with the Masked Autoencoder (MAE) Framework using Lightning (PyTorch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lightning import Trainer\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from mae import MaskedAutoencoderLIT\n",
    "\n",
    "# Define the transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# Initialize the Masked Autoencoder model with the specified parameters\n",
    "model = MaskedAutoencoderLIT(\n",
    "    size='base',\n",
    "    in_chans=1,\n",
    "    base_lr=3e-5,\n",
    "    num_gpus=1,\n",
    "    batch_size=512,\n",
    "    warmup_epochs=1,\n",
    "    weight_decay=0.05,\n",
    "    betas=(0.9, 0.95)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = Trainer(max_epochs=10, gpus=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'masked_autoencoder.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mae_to_vit import get_vit_from_mae\n",
    "\n",
    "# Load the trained model to get ViT, Set Global Pooling to False for Linear Probing\n",
    "vit_for_linear_probe = get_vit_from_mae(pretrained_model=model.state_dict(), global_pool=False)\n",
    "\n",
    "# Load the trained model to get ViT, Set Global Pooling to True for Fine-Tuning\n",
    "vit_for_linear_probe = get_vit_from_mae(pretrained_model=model.state_dict(), global_pool=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
